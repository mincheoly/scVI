{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A semi-supervised framework for the annotation problem\n",
    "\n",
    "**NB**: please refer to the scVI-dev notebook for introduction of the scVI package.\n",
    "\n",
    "In this notebook, we investigate how semi-supervised learning combined with the probabilistic modelling of latent variables in scVI can help address the annotation problem.\n",
    "\n",
    "The annotation problem consists in labelling cells, ie. **inferring their cell types**, knowing only a part of the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/scVI\n"
     ]
    }
   ],
   "source": [
    "cd ~/scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_benchmarks import load_datasets\n",
    "from scvi.models import SVAEC, VAE\n",
    "from scvi.inference import JointSemiSupervisedVariationalInference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate the SVAEC model and train it over 250 epochs. Only labels from the `data_loader_labelled` will be used, but to cross validate the results, the labels of `data_loader_unlabelled` will is used at test time. The accuracy of the `unlabelled` dataset reaches 93% here at the end of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/expression.bin already downloaded\n",
      "training: 100%|██████████| 50/50 [00:19<00:00,  2.50it/s]\n",
      "Acc for unlabelled is : 0.9376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9376490712165833"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_dataset = load_datasets('cortex')\n",
    "\n",
    "use_batches=False\n",
    "use_cuda=True\n",
    "\n",
    "svaec = SVAEC(gene_dataset.nb_genes, gene_dataset.n_labels)\n",
    "infer = JointSemiSupervisedVariationalInference(svaec, gene_dataset, n_labelled_samples_per_class=10)\n",
    "infer.fit(n_epochs=50)\n",
    "\n",
    "infer.accuracy('unlabelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking against other algorithms\n",
    "\n",
    "We can compare ourselves against the random forest and SVM algorithms, where we do grid search with 3-fold cross validation to find the best hyperparameters of these algorithms. This is automatically performed through the functions **`compute_accuracy_svc`** and **`compute_accuracy_rf`**.\n",
    "\n",
    "These functions should be given as input the numpy array corresponding to the equivalent dataloaders, which is the purpose of the **`get_raw_data`** method from `scvi.dataset.utils`.\n",
    "\n",
    "The format of the result is an Accuracy named tuple object giving higher granularity information about the accuracy ie, with attributes:\n",
    "\n",
    "- **unweighted**: the standard definition of accuracy\n",
    "\n",
    "- **weighted**: we might give the same weight to all classes in the final accuracy results. Informative only if the dataset is unbalanced.\n",
    "\n",
    "- **worst**: the worst accuracy score for the classes\n",
    "\n",
    "- **accuracy_classes** : give the detail of the accuracy per classes\n",
    "\n",
    "\n",
    "Compute the accuracy score for rf and svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC score test :\n",
      " Accuracy(unweighted=0.87018739352640551, weighted=0.84659088617012479, worst=0.72236503856041134, accuracy_classes=[0.79439252336448596, 0.90666666666666662, 0.88571428571428568, 0.79545454545454541, 0.9345679012345679, 0.88697524219590962, 0.72236503856041134])\n",
      "\n",
      "RF score train :\n",
      " Accuracy(unweighted=0.92810902896081771, weighted=0.89784424707013932, worst=0.79545454545454541, accuracy_classes=[0.87383177570093462, 0.90222222222222226, 0.98571428571428577, 0.79545454545454541, 0.96049382716049381, 0.96770721205597421, 0.7994858611825193])\n"
     ]
    }
   ],
   "source": [
    "svc_scores, rf_scores = infer.svc_rf()\n",
    "print(\"\\nSVC score test :\\n\", svc_scores[1])\n",
    "print(\"\\nRF score train :\\n\", rf_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
